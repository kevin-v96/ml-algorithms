{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bed8ce13",
   "metadata": {},
   "source": [
    "# Lasso parameter selection and Inductive Conformal Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa8fb4b",
   "metadata": {},
   "source": [
    "### 1\n",
    "Firstly, we'll load the scikit-learn version of the diabetes dataset with load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e99b672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51f20549",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e8e2b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, total serum cholesterol\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, total cholesterol / HDL\n",
      "      - s5      ltg, possibly log of serum triglycerides level\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "print(diabetes.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96edbb98",
   "metadata": {},
   "source": [
    "### 2\n",
    "Let's split it into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d72d88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, random_state=307)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97630bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "lasso = Lasso().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30d30606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36779324829211146"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f18652dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3362814529900525"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd42b8a",
   "metadata": {},
   "source": [
    "### 3\n",
    "As we can see, the raining and test set scores for the default Lasso and the scikit diabetes dataset are 0.367 and 0.336, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "475a5280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(lasso.coef_ != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d79796a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,  -0.        , 397.79090115,   2.42286963,\n",
       "         0.        ,   0.        ,  -0.        ,   0.        ,\n",
       "       292.26659239,   0.        ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b52a53c",
   "metadata": {},
   "source": [
    "The 3rd, 4th and 9th features. i.e, bmi, bp, and ltg, possibly log of serum triglycerides level are used by the Lasso model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf84f961",
   "metadata": {},
   "source": [
    "### 4\n",
    "\n",
    "We will now load the original (not normalized) diabetes dataset we got from https://trevorhastie.github.io/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79ea0a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_original = np.genfromtxt(\"diabetes.data\", skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25d81ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59.    ,   2.    ,  32.1   , ...,   4.8598,  87.    , 151.    ],\n",
       "       [ 48.    ,   1.    ,  21.6   , ...,   3.8918,  69.    ,  75.    ],\n",
       "       [ 72.    ,   2.    ,  30.5   , ...,   4.6728,  85.    , 141.    ],\n",
       "       ...,\n",
       "       [ 60.    ,   2.    ,  24.9   , ...,   4.1271,  95.    , 132.    ],\n",
       "       [ 36.    ,   1.    ,  30.    , ...,   5.1299,  85.    , 220.    ],\n",
       "       [ 36.    ,   1.    ,  19.6   , ...,   4.5951,  92.    ,  57.    ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diab_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a9c96c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diab_original[:, 0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3bf9f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diab_original[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34c902bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234c2275",
   "metadata": {},
   "source": [
    "### 5\n",
    "Let's split the dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fc41721",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=307)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be7c0624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score is:  0.5154674892898614\n",
      "The test score is:  0.48589838321772183\n",
      "The number of features used is:  9\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso().fit(X_train, y_train)\n",
    "print(\"The training score is: \", lasso.score(X_train, y_train))\n",
    "print(\"The test score is: \",lasso.score(X_test, y_test))\n",
    "print(\"The number of features used is: \", np.sum(lasso.coef_ != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ea87e5",
   "metadata": {},
   "source": [
    "### 6\n",
    "After repeating step no. 3 for the unnormalised dataset, we see that the scores seen here with the default parameters are a little higher than the ones seen in the above normalised dataset, and the features that are used increase drastically from 3 to almost the whole set of features, 9/10. At this point, it might as well be Ridge regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99011c52",
   "metadata": {},
   "source": [
    "### 7\n",
    "Let's preprocess the dataset using StandarScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4dc42cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4616b1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score is:  0.5178054444563157\n",
      "The test score is:  0.49007071104495203\n",
      "The number of features used is:  8\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso().fit(X_train_scaled, y_train)\n",
    "print(\"The training score is: \", lasso.score(X_train_scaled, y_train))\n",
    "print(\"The test score is: \",lasso.score(X_test_scaled, y_test))\n",
    "print(\"The number of features used is: \", np.sum(lasso.coef_ != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3282780",
   "metadata": {},
   "source": [
    "### 8\n",
    "Repeating the steps from item 3, we see that these results are closer to the results from item 6, with 8 features used instead of 9 and almost the same training and test scores. We would expect the results to be similar to the ones from item 3, since the main difference between the previous results was that the initial one was gotten by training a Lasso on normalized data, while the other one was on data that was not normalized.\n",
    "\n",
    "This is likely because we used the StandardScaler, which makes the mean of features 0 and variance 1, whereas the already normalized data that we started out with had Normalization done on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "27ee63f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 15, 20, 30, 50, 100]\n",
      "[10, 10, 10, 10, 10, 10, 8, 4, 3, 3, 2, 0, 0]\n",
      "[0.4951313427502605, 0.4951311256515436, 0.49512895432459103, 0.4951072014511807, 0.4948855839971581, 0.4934912167778295, 0.49007071104495203, 0.43136227253358117, 0.3906628202321326, 0.34311366679625843, 0.22874632816243756, -0.004709748419508664, -0.004709748419508664]\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.000001, 0.00001, 0.0001,0.001,0.01,0.1,1,10,15, 20, 30, 50, 100]\n",
    "usedCoefs = []\n",
    "scores = []\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha, max_iter = 100000).fit(X_train_scaled, y_train)\n",
    "    usedCoefs.append(np.sum(lasso.coef_ != 0))\n",
    "    scores.append(lasso.score(X_test_scaled, y_test))\n",
    "print(alphas)\n",
    "print(usedCoefs)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "40bc2467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, 1.0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(usedCoefs, scores, 'v')\n",
    "plt.xlabel(\"Number of used coefficients\") \n",
    "plt.ylabel(\"R squared error\")\n",
    "plt.ylim(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1da1287",
   "metadata": {},
   "source": [
    "### 9\n",
    "Here, we see that the number of used coefficients goes down from 10 all the way to 0 for different alphas, with the corresponding R squared error going from 0.5 to 0. alpha = 30, for which the number of used coefficients are 2, or alpha = 15 or 20, for which number of coefficients are 3, would be preferable as they minimise the error enough (to about 0.25) while not overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bd45fe",
   "metadata": {},
   "source": [
    "### 10 Param selection using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "35190f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Lasso(),\n",
       "             param_grid={'alpha': [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                   10, 15, 20, 30, 40, 50],\n",
       "                         'max_iter': [100000]})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'alpha': [0.000001, 0.00001, 0.0001,0.001,0.01,0.1,1,10,15, 20, 30, 40, 50], 'max_iter': [100000]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(Lasso(), param_grid, cv = 5)\n",
    "grid_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "027b1024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49007071104495203"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "18b018b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1, max_iter=100000)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "af82cb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47111670499038694"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6de3ce43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1, 'max_iter': 100000}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ccf757",
   "metadata": {},
   "source": [
    "As we can see, the cross-validation gives us the best result at alpha = 1 with the test score of 0.49. The score that we got in item 9 might either be because of accident since there was no cross-validation, or because it was overfit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eade9dc9",
   "metadata": {},
   "source": [
    "### 11 Inductive Conformal Predictor\n",
    "Now let us implement an inductive conformal predictor based on Lasso by dividing the training set we got in step 5 into a training set proper and a calibration set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c4fc6f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_proper, X_cal, y_train_proper, y_cal = train_test_split(X_train, y_train, test_size=99, random_state=307)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e8f01a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e801a6c",
   "metadata": {},
   "source": [
    "Let us first fit the StandardScaler to the training set proper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722fbeab",
   "metadata": {},
   "source": [
    "scaler.fit(X_train_proper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1176ede",
   "metadata": {},
   "source": [
    "Now let us scale the training set proper, calibration set, and test set based on this fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e0b86964",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_proper_scaled = scaler.transform(X_train_proper)\n",
    "X_cal_scaled = scaler.transform(X_cal)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dcdf004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_conformal = GridSearchCV(Lasso(), param_grid, cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e6121c",
   "metadata": {},
   "source": [
    "We'll use GridSearchCV and fit it to the training set proper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4546b11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Lasso(),\n",
       "             param_grid={'alpha': [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                   10, 15, 20, 30, 40, 50],\n",
       "                         'max_iter': [100000]})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_conformal.fit(X_train_proper_scaled, y_train_proper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963bcc37",
   "metadata": {},
   "source": [
    "Now let us get the predictions for the calibration set based on this lasso. i.e, y hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a0358aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_predictions = grid_search.predict(X_cal_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "64bd2889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.23295369, 219.58465909, 215.8813095 , 142.25922911,\n",
       "       107.13334653,  65.04396185, 146.37201843, 155.92509467,\n",
       "       126.76597211, 162.05119461, 122.7368154 ,  86.81228883,\n",
       "       184.95826597,  41.8313076 , 117.11174947,  62.72754671,\n",
       "       218.6643225 , 265.45620525, 249.18790427,  77.40800695,\n",
       "       188.19912327, 202.23468317, 262.45722   , 261.13951468,\n",
       "       174.72316058, 126.19376632, 220.55171971, 128.35049031,\n",
       "       203.51136369, 117.81516094, 280.07881095, 100.9235782 ,\n",
       "        54.6853528 , 139.22181447,  56.24088887, 284.32135025,\n",
       "       200.74407409,  72.51137888, 180.00347625, 156.71946583,\n",
       "       259.95611428, 188.65307429, 165.77607668, 122.8743461 ,\n",
       "       216.38010737, 165.41962805,  90.28543004, 206.49244366,\n",
       "        69.66124195, 251.62064302, 124.88658926, 173.46992247,\n",
       "        94.663204  ,  72.16486958, 213.14891474,  71.58888368,\n",
       "       270.76040473, 207.42579534, 155.24483951, 193.60980522,\n",
       "       189.51350834, 142.12564344, 225.0255382 ,  74.94357942,\n",
       "       166.99802333, 142.41192775, 176.325631  , 165.66439378,\n",
       "       110.33123646,  68.11874619, 119.73731226,  49.89897247,\n",
       "       235.01377481, 103.78505708, 168.80603226,  72.14830746,\n",
       "        61.55077087, 176.35960641, 197.59670589, 116.71970955,\n",
       "       179.07148456, 185.10011561, 132.87707266, 156.04442025,\n",
       "       144.54917751, 231.70777738, 249.38059458, 240.84491837,\n",
       "       177.05163616, 133.22911054,  95.64223357, 132.22734979,\n",
       "       137.54109226, 140.12572767, 166.91022397, 153.99688095,\n",
       "       106.7705334 ,  94.99509523,  49.30016057])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5875e9a1",
   "metadata": {},
   "source": [
    "Let us find the alpha_i nonconformity scores for the calibration set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "751c8051",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_i = np.absolute(y_cal - cal_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0d09bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_i_sorted = np.sort(alpha_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "931cb98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = len(alpha_i)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72f2adc",
   "metadata": {},
   "source": [
    "For ε = 0.05, k = ceil((1-0.05)(99+1)) = 95 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "09e868e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 95\n",
    "c_5 = alpha_i_sorted[k-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4b0421ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.77607667623496"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbedb777",
   "metadata": {},
   "source": [
    "Here, we found c as the 95th conformity score (since indexing starts from 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ee09e4",
   "metadata": {},
   "source": [
    "The length of prediction intervals for ε = 0.05 will be 2c = 2 * 88.78 = 177.56"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaac4e2",
   "metadata": {},
   "source": [
    "For the 20% prediction interval, ε = 0.2, thus, k = ceil((1-0.2)(99+1)) = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "93443679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.00490477472586"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 80\n",
    "c_20 = alpha_i_sorted[k-1]\n",
    "c_20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211d5c7c",
   "metadata": {},
   "source": [
    "For the 20% prediction interval, the length of the interval is 2 * c = 2 * 63 = 126"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e5420c",
   "metadata": {},
   "source": [
    "Now, to find the test error rate for our conformal predictor, let us first find the predicted labels for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "02ce249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = grid_search_conformal.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4796b081",
   "metadata": {},
   "source": [
    "For these predictions, we'll go through each prediction, calculate the prediction interval, and see if the actual label lies inside this interval. We'll count the fraction of predictions that don't lie inside their prediction interval to get the error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4c10c281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error count for 20% is 30\n",
      "error count for 5% is 12\n"
     ]
    }
   ],
   "source": [
    "error_count_5 = 0\n",
    "error_count_20 = 0\n",
    "for i in range(len(test_predictions)):\n",
    "    prediction = test_predictions[i]\n",
    "    if(y_test[i] < prediction - c_5 or y_test[i] > prediction + c_5):\n",
    "        error_count_5 += 1\n",
    "    if(y_test[i] < prediction - c_20 or y_test[i] > prediction + c_20):\n",
    "        error_count_20 += 1\n",
    "print(\"error count for 20% is\",error_count_20)\n",
    "print(\"error count for 5% is\",error_count_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b8e867a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate for 20% is 0.2702702702702703\n",
      "The error rate for 5% is 0.10810810810810811\n"
     ]
    }
   ],
   "source": [
    "error_rate_20 = error_count_20 / len(test_predictions)\n",
    "error_rate_5 = error_count_5 / len(test_predictions)\n",
    "print(\"The error rate for 20% is\", error_rate_20)\n",
    "print(\"The error rate for 5% is\", error_rate_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1004a6a",
   "metadata": {},
   "source": [
    "As we can see, the error rate for the 20% prediction interval is 0.27, while the error rate for 5% prediction interval is 0.11, as we would expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ea594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
